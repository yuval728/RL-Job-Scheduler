{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d128e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import random\n",
    "from stable_baselines3 import PPO, A2C, SAC, DQN, TD3, DDPG\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class JobSchedulingEnv(gym.Env):\n",
    "    def __init__(self, num_jobs=5):\n",
    "        super(JobSchedulingEnv, self).__init__()\n",
    "        self.num_jobs = num_jobs\n",
    "\n",
    "        # Each job has 6 features:\n",
    "        # (arrival_time, execution_time, priority, deadline, cpu_requirement, job_type)\n",
    "        # job_type: 0 for I/O-bound, 1 for CPU-bound\n",
    "        self.jobs = []\n",
    "        self.backup_jobs = []\n",
    "\n",
    "        # Joint action space:\n",
    "        # First num_jobs dimensions: scheduling scores (continuous in [0,1])\n",
    "        # Last dimension: resource allocation decision (continuous in [0,1])\n",
    "        self.action_space = spaces.Box(\n",
    "            low=0, high=1, shape=(num_jobs + 1,), dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # Observation space: Each job is represented by 6 features.\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=100, shape=(num_jobs, 6), dtype=np.float32\n",
    "        )\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        arrival_times = np.sort(\n",
    "            np.random.normal(loc=5, scale=2, size=self.num_jobs)\n",
    "        )  # Clustered arrivals\n",
    "        arrival_times = np.clip(arrival_times, 0, 10) / 10  # Normalize to [0,1]\n",
    "\n",
    "        execution_times = (\n",
    "            np.clip(np.random.normal(loc=5, scale=2, size=self.num_jobs), 1, 10) / 10\n",
    "        )\n",
    "        priorities = (\n",
    "            np.random.choice(\n",
    "                [1, 2, 3, 4, 5], self.num_jobs, p=[0.1, 0.2, 0.4, 0.2, 0.1]\n",
    "            )\n",
    "            / 5\n",
    "        )\n",
    "        deadlines = (\n",
    "            arrival_times\n",
    "            + execution_times\n",
    "            + np.random.randint(3, 10, size=self.num_jobs)\n",
    "        ) / 20\n",
    "        cpu_requirements = np.random.randint(1, 11, size=self.num_jobs) / 10\n",
    "        job_types = np.random.choice([0, 1], self.num_jobs)  # I/O or CPU bound\n",
    "\n",
    "        self.jobs = list(\n",
    "            zip(\n",
    "                arrival_times,\n",
    "                execution_times,\n",
    "                priorities,\n",
    "                deadlines,\n",
    "                cpu_requirements,\n",
    "                job_types,\n",
    "            )\n",
    "        )\n",
    "        self.jobs.sort(key=lambda x: x[0])\n",
    "        self.backup_jobs = self.jobs.copy()  # keep a backup for baselines\n",
    "        self.time = 0  # simulation time\n",
    "        self.done_jobs = []\n",
    "        self.total_waiting_time = 0\n",
    "\n",
    "        return self._get_observation(), {}\n",
    "\n",
    "    def _get_observation(self):\n",
    "        obs = np.zeros((self.num_jobs, 6), dtype=np.float32)\n",
    "        for i, job in enumerate(self.jobs):\n",
    "            obs[i] = job\n",
    "        return obs\n",
    "\n",
    "    # def _get_observation(self):\n",
    "    #     if len(self.jobs) == 0:\n",
    "    #         return np.zeros((self.num_jobs, 6), dtype=np.float32)\n",
    "    #     obs = np.array([job for job in self.jobs], dtype=np.float32)\n",
    "\n",
    "    #     if len(obs) < self.num_jobs:\n",
    "    #         padding = np.zeros((self.num_jobs - len(obs), 6), dtype=np.float32)\n",
    "    #         obs = np.vstack([obs, padding])\n",
    "    #     return obs\n",
    "    def step(self, action):\n",
    "        scheduling_scores = action[: self.num_jobs]\n",
    "        resource_allocation = action[-1]\n",
    "\n",
    "        job_index = int(np.argmax(scheduling_scores))\n",
    "\n",
    "        if job_index >= len(self.jobs):\n",
    "            return self._get_observation(), -10, True, False, {}\n",
    "\n",
    "        selected_job = self.jobs.pop(job_index)\n",
    "        arrival_time, execution_time, priority, deadline, cpu_req, job_type = (\n",
    "            selected_job\n",
    "        )\n",
    "\n",
    "        # Advance simulation time\n",
    "        self.time = max(self.time, arrival_time) + execution_time\n",
    "\n",
    "        # Compute waiting time and base reward.\n",
    "        waiting_time = self.time - arrival_time - execution_time\n",
    "        self.total_waiting_time += waiting_time\n",
    "        base_reward = -waiting_time - (execution_time / priority) - len(self.jobs) * 0.1\n",
    "\n",
    "        # Deadline-based reward adjustment:\n",
    "        if self.time > deadline:\n",
    "            base_reward -= 10  # penalty for missing deadline\n",
    "        else:\n",
    "            base_reward += 5  # bonus for meeting deadline\n",
    "\n",
    "        # Energy consumption penalty based on resource allocation decision.\n",
    "        # Assume an optimal resource allocation value. Deviations incur a penalty.\n",
    "        optimal_resource = 0.7\n",
    "        energy_penalty = 5 * abs(resource_allocation - optimal_resource)\n",
    "\n",
    "        throughput_reward = 10 / (self.time + 1)\n",
    "        # efficiency_bonus = 5 * (1 - abs(resource_allocation - optimal_resource))\n",
    "\n",
    "        reward = base_reward + throughput_reward - energy_penalty\n",
    "\n",
    "        self.done_jobs.append(selected_job)\n",
    "        done = len(self.jobs) == 0\n",
    "\n",
    "        return self._get_observation(), reward, done, False, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "932c396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fifo_scheduling(jobs):\n",
    "    time = 0\n",
    "    total_waiting_time = 0\n",
    "    for job in sorted(jobs, key=lambda x: x[0]):  # sort by arrival_time\n",
    "        arrival_time, execution_time, priority, deadline = job[:4]\n",
    "        time = max(time, arrival_time) + execution_time\n",
    "        total_waiting_time += time - arrival_time - execution_time\n",
    "    return total_waiting_time\n",
    "\n",
    "\n",
    "def sjf_scheduling(jobs):\n",
    "    time = 0\n",
    "    total_waiting_time = 0\n",
    "    for job in sorted(jobs, key=lambda x: x[1]):  # sort by execution_time\n",
    "        arrival_time, execution_time, priority, deadline = job[:4]\n",
    "        time = max(time, arrival_time) + execution_time\n",
    "        total_waiting_time += time - arrival_time - execution_time\n",
    "    return total_waiting_time\n",
    "\n",
    "\n",
    "def edf_scheduling(jobs):\n",
    "    time = 0\n",
    "    total_waiting_time = 0\n",
    "    for job in sorted(jobs, key=lambda x: x[3]):  # sort by deadline\n",
    "        arrival_time, execution_time, priority, deadline = job[:4]\n",
    "        time = max(time, arrival_time) + execution_time\n",
    "        if time > deadline:\n",
    "            total_waiting_time += (\n",
    "                time - deadline\n",
    "            ) * 2  # heavier penalty for missing deadline\n",
    "        else:\n",
    "            total_waiting_time += time - arrival_time - execution_time\n",
    "    return total_waiting_time\n",
    "\n",
    "\n",
    "def rr_scheduling(jobs, quantum=1):\n",
    "    time = 0\n",
    "    total_waiting_time = 0\n",
    "    queue = jobs.copy()\n",
    "\n",
    "    while queue:\n",
    "        job = queue.pop(0)\n",
    "        arrival_time, execution_time, priority, deadline = job[:4]\n",
    "\n",
    "        if time < arrival_time:\n",
    "            time = arrival_time\n",
    "\n",
    "        if execution_time > quantum:\n",
    "            time += quantum\n",
    "            queue.append((arrival_time, execution_time - quantum, priority, deadline))\n",
    "        else:\n",
    "            time += execution_time\n",
    "            total_waiting_time += time - arrival_time - execution_time\n",
    "\n",
    "    return total_waiting_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7d1f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddfa249c5c6346a89c26baf0c97cd2d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3f4258c4624e9a914a351532393113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab6e93978c945eb889e75f2954c2495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "algos = {\"PPO\": PPO, \"A2C\": A2C, \"SAC\": SAC, \"DQN\": DQN, \"TD3\": TD3,  \"DDPG\": DDPG}\n",
    "results = {}\n",
    "\n",
    "\n",
    "env = JobSchedulingEnv(num_jobs=5)\n",
    "\n",
    "for name, algo in algos.items():\n",
    "    model = algo(\"MlpPolicy\", env, verbose=0, tensorboard_log=\"./tb_logs/\")\n",
    "    model.set_random_seed(42)\n",
    "    model.learn(total_timesteps=5000, progress_bar=True)\n",
    "\n",
    "    total_reward = 0\n",
    "    for _ in range(10):\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs)\n",
    "            obs, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            total_reward += reward\n",
    "\n",
    "    results[name] = total_reward\n",
    "\n",
    "plt.bar(results.keys(), results.values())\n",
    "plt.xlabel(\"Algorithm\")\n",
    "plt.ylabel(\"Total Reward\")\n",
    "plt.title(\"Comparison of RL Algorithms\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be5ce039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4457c4a02ea646dcb8b1481fb4245973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m     model = PPO(POLICY, env, verbose=\u001b[32m0\u001b[39m, tensorboard_log=\u001b[33m\"\u001b[39m\u001b[33m./tb_logs/\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m model.set_random_seed(\u001b[32m42\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# obs, _ = env.reset()\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# done = False\u001b[39;00m\n\u001b[32m     19\u001b[39m rewards = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yuval\\Desktop\\SEM XII\\RL\\Job-Scheduler\\.venv\\Lib\\site-packages\\stable_baselines3\\sac\\sac.py:308\u001b[39m, in \u001b[36mSAC.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    299\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlearn\u001b[39m(\n\u001b[32m    300\u001b[39m     \u001b[38;5;28mself\u001b[39m: SelfSAC,\n\u001b[32m    301\u001b[39m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    306\u001b[39m     progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    307\u001b[39m ) -> SelfSAC:\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yuval\\Desktop\\SEM XII\\RL\\Job-Scheduler\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:328\u001b[39m, in \u001b[36mOffPolicyAlgorithm.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.train_freq, TrainFreq)  \u001b[38;5;66;03m# check done in _setup_learn()\u001b[39;00m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m.num_timesteps < total_timesteps:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     rollout = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_freq\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m        \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maction_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rollout.continue_training:\n\u001b[32m    339\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yuval\\Desktop\\SEM XII\\RL\\Job-Scheduler\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:557\u001b[39m, in \u001b[36mOffPolicyAlgorithm.collect_rollouts\u001b[39m\u001b[34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[39m\n\u001b[32m    554\u001b[39m     \u001b[38;5;28mself\u001b[39m.actor.reset_noise(env.num_envs)  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[32m    556\u001b[39m \u001b[38;5;66;03m# Select action randomly or according to policy\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m actions, buffer_actions = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_envs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n\u001b[32m    560\u001b[39m new_obs, rewards, dones, infos = env.step(actions)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yuval\\Desktop\\SEM XII\\RL\\Job-Scheduler\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:390\u001b[39m, in \u001b[36mOffPolicyAlgorithm._sample_action\u001b[39m\u001b[34m(self, learning_starts, action_noise, n_envs)\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    386\u001b[39m     \u001b[38;5;66;03m# Note: when using continuous actions,\u001b[39;00m\n\u001b[32m    387\u001b[39m     \u001b[38;5;66;03m# we assume that the policy uses tanh to scale the action\u001b[39;00m\n\u001b[32m    388\u001b[39m     \u001b[38;5;66;03m# We use non-deterministic action in the case of SAC, for TD3, it does not matter\u001b[39;00m\n\u001b[32m    389\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._last_obs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mself._last_obs was not set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m     unscaled_action, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_last_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[38;5;66;03m# Rescale the action from [low, high] to [-1, 1]\u001b[39;00m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.action_space, spaces.Box):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yuval\\Desktop\\SEM XII\\RL\\Job-Scheduler\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\base_class.py:557\u001b[39m, in \u001b[36mBaseAlgorithm.predict\u001b[39m\u001b[34m(self, observation, state, episode_start, deterministic)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\n\u001b[32m    538\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    539\u001b[39m     observation: Union[np.ndarray, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, np.ndarray]],\n\u001b[32m   (...)\u001b[39m\u001b[32m    542\u001b[39m     deterministic: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    543\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[np.ndarray, Optional[\u001b[38;5;28mtuple\u001b[39m[np.ndarray, ...]]]:\n\u001b[32m    544\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    545\u001b[39m \u001b[33;03m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[32m    546\u001b[39m \u001b[33;03m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    555\u001b[39m \u001b[33;03m        (used in recurrent policies)\u001b[39;00m\n\u001b[32m    556\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yuval\\Desktop\\SEM XII\\RL\\Job-Scheduler\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:368\u001b[39m, in \u001b[36mBasePolicy.predict\u001b[39m\u001b[34m(self, observation, state, episode_start, deterministic)\u001b[39m\n\u001b[32m    365\u001b[39m obs_tensor, vectorized_env = \u001b[38;5;28mself\u001b[39m.obs_to_tensor(observation)\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m th.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m     actions = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[38;5;66;03m# Convert to numpy, and reshape to the original action shape\u001b[39;00m\n\u001b[32m    370\u001b[39m actions = actions.cpu().numpy().reshape((-\u001b[32m1\u001b[39m, *\u001b[38;5;28mself\u001b[39m.action_space.shape))  \u001b[38;5;66;03m# type: ignore[misc, assignment]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yuval\\Desktop\\SEM XII\\RL\\Job-Scheduler\\.venv\\Lib\\site-packages\\stable_baselines3\\sac\\policies.py:353\u001b[39m, in \u001b[36mSACPolicy._predict\u001b[39m\u001b[34m(self, observation, deterministic)\u001b[39m\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, observation: PyTorchObs, deterministic: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m) -> th.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mactor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yuval\\Desktop\\SEM XII\\RL\\Job-Scheduler\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yuval\\Desktop\\SEM XII\\RL\\Job-Scheduler\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yuval\\Desktop\\SEM XII\\RL\\Job-Scheduler\\.venv\\Lib\\site-packages\\stable_baselines3\\sac\\policies.py:170\u001b[39m, in \u001b[36mActor.forward\u001b[39m\u001b[34m(self, obs, deterministic)\u001b[39m\n\u001b[32m    168\u001b[39m mean_actions, log_std, kwargs = \u001b[38;5;28mself\u001b[39m.get_action_dist_params(obs)\n\u001b[32m    169\u001b[39m \u001b[38;5;66;03m# Note: the action is squashed\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maction_dist\u001b[49m\u001b[43m.\u001b[49m\u001b[43mactions_from_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_std\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yuval\\Desktop\\SEM XII\\RL\\Job-Scheduler\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\distributions.py:191\u001b[39m, in \u001b[36mDiagGaussianDistribution.actions_from_params\u001b[39m\u001b[34m(self, mean_actions, log_std, deterministic)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mactions_from_params\u001b[39m(\u001b[38;5;28mself\u001b[39m, mean_actions: th.Tensor, log_std: th.Tensor, deterministic: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m) -> th.Tensor:\n\u001b[32m    189\u001b[39m     \u001b[38;5;66;03m# Update the proba distribution\u001b[39;00m\n\u001b[32m    190\u001b[39m     \u001b[38;5;28mself\u001b[39m.proba_distribution(mean_actions, log_std)\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_actions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yuval\\Desktop\\SEM XII\\RL\\Job-Scheduler\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\distributions.py:89\u001b[39m, in \u001b[36mDistribution.get_actions\u001b[39m\u001b[34m(self, deterministic)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deterministic:\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode()\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yuval\\Desktop\\SEM XII\\RL\\Job-Scheduler\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\distributions.py:249\u001b[39m, in \u001b[36mSquashedDiagGaussianDistribution.sample\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msample\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> th.Tensor:\n\u001b[32m    248\u001b[39m     \u001b[38;5;66;03m# Reparametrization trick to pass gradients\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     \u001b[38;5;28mself\u001b[39m.gaussian_actions = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m th.tanh(\u001b[38;5;28mself\u001b[39m.gaussian_actions)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yuval\\Desktop\\SEM XII\\RL\\Job-Scheduler\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\distributions.py:183\u001b[39m, in \u001b[36mDiagGaussianDistribution.sample\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msample\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> th.Tensor:\n\u001b[32m    182\u001b[39m     \u001b[38;5;66;03m# Reparametrization trick to pass gradients\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdistribution\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrsample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yuval\\Desktop\\SEM XII\\RL\\Job-Scheduler\\.venv\\Lib\\site-packages\\torch\\distributions\\normal.py:77\u001b[39m, in \u001b[36mNormal.rsample\u001b[39m\u001b[34m(self, sample_shape)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrsample\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample_shape: _size = torch.Size()) -> torch.Tensor:\n\u001b[32m     76\u001b[39m     shape = \u001b[38;5;28mself\u001b[39m._extended_shape(sample_shape)\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     eps = \u001b[43m_standard_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loc + eps * \u001b[38;5;28mself\u001b[39m.scale\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yuval\\Desktop\\SEM XII\\RL\\Job-Scheduler\\.venv\\Lib\\site-packages\\torch\\distributions\\utils.py:65\u001b[39m, in \u001b[36m_standard_normal\u001b[39m\u001b[34m(shape, dtype, device)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch._C._get_tracing_state():\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# [JIT WORKAROUND] lack of support for .normal_()\u001b[39;00m\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.normal(\n\u001b[32m     62\u001b[39m         torch.zeros(shape, dtype=dtype, device=device),\n\u001b[32m     63\u001b[39m         torch.ones(shape, dtype=dtype, device=device),\n\u001b[32m     64\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m.normal_()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "ALGO = \"SAC\"\n",
    "POLICY = \"MlpPolicy\"\n",
    "\n",
    "\n",
    "env = JobSchedulingEnv(num_jobs=5)\n",
    "\n",
    "model = algos[ALGO](POLICY, env, verbose=1, tensorboard_log=\"./tb_logs/\")\n",
    "\n",
    "model.set_random_seed(42)\n",
    "model.learn(total_timesteps=20000, progress_bar=True)\n",
    "\n",
    "# obs, _ = env.reset()\n",
    "# done = False\n",
    "rewards = []\n",
    "\n",
    "for _ in range(10):  # Test for 10 episodes\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        episode_reward += reward\n",
    "    rewards.append(episode_reward)\n",
    "\n",
    "print(\"Average Reward:\", np.mean(rewards))\n",
    "print(\"Total Waiting Time:\", env.total_waiting_time)\n",
    "print(\"Done Jobs:\", len(env.done_jobs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59abc39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_per_episode = []\n",
    "obs, _ = env.reset()\n",
    "for _ in range(100):  # 100 test episodes\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, done, _, _ = env.step(action)\n",
    "    rewards_per_episode.append(reward)\n",
    "\n",
    "plt.plot(rewards_per_episode, label=\"Rewards per Episode\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b82bcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(rewards, label=\"RL Agent Reward per Step\")\n",
    "fifo = -fifo_scheduling(env.jobs)\n",
    "sjf = -sjf_scheduling(env.jobs)\n",
    "edf = -edf_scheduling(env.jobs)\n",
    "plt.axhline(y=fifo, color=\"r\", linestyle=\"--\", label=\"FIFO Baseline\")\n",
    "plt.axhline(y=sjf, color=\"g\", linestyle=\"--\", label=\"SJF Baseline\")\n",
    "plt.axhline(y=edf, color=\"b\", linestyle=\"--\", label=\"EDF Baseline\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Reward Over Time in Job Scheduling\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1510c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"js_model_{ALGO}.zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffc9fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = algos[ALGO].load(f\"js_model_{ALGO}.zip\", env=env)\n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "rewards = []\n",
    "while not done:\n",
    "    action, _ = loaded_model.predict(obs)\n",
    "    obs, reward, terminated, truncated, _ = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    rewards.append(reward)\n",
    "print(\"Loaded Model Average Reward:\", np.mean(rewards))\n",
    "print(\"Loaded Model Total Waiting Time:\", env.total_waiting_time)\n",
    "print(\"Loaded Model Done Jobs:\", len(env.done_jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d660a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
